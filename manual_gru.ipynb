{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "111af09c22071ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fungsi Perhitungan GRU Sudah disiapkan\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    x = np.clip(x, -500, 500)\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    x = np.clip(x, -500, 500)\n",
    "    return np.tanh(x)\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sig = sigmoid(x)\n",
    "    return sig * (1 - sig)\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return 1 - tanh(x)**2\n",
    "\n",
    "class GRUCell:\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Xavier/Glorot initialization\n",
    "        limit = np.sqrt(6 / (input_dim + hidden_dim))\n",
    "        self.Wz = np.random.uniform(-limit, limit, (hidden_dim, input_dim))\n",
    "        self.Uz = np.random.uniform(-limit, limit, (hidden_dim, hidden_dim))\n",
    "        self.bz = np.zeros((hidden_dim, 1))\n",
    "\n",
    "        self.Wr = np.random.uniform(-limit, limit, (hidden_dim, input_dim))\n",
    "        self.Ur = np.random.uniform(-limit, limit, (hidden_dim, hidden_dim))\n",
    "        self.br = np.zeros((hidden_dim, 1))\n",
    "\n",
    "        self.Wh = np.random.uniform(-limit, limit, (hidden_dim, input_dim))\n",
    "        self.Uh = np.random.uniform(-limit, limit, (hidden_dim, hidden_dim))\n",
    "        self.bh = np.zeros((hidden_dim, 1))\n",
    "\n",
    "        # Adam optimizer parameters\n",
    "        self.m = {param: np.zeros_like(getattr(self, param)) for param in ['Wz', 'Uz', 'bz', 'Wr', 'Ur', 'br', 'Wh', 'Uh', 'bh']}\n",
    "        self.v = {param: np.zeros_like(getattr(self, param)) for param in ['Wz', 'Uz', 'bz', 'Wr', 'Ur', 'br', 'Wh', 'Uh', 'bh']}\n",
    "        self.t = 0\n",
    "\n",
    "        self.reset_gradients()\n",
    "\n",
    "    def reset_gradients(self):\n",
    "        self.dWz = np.zeros_like(self.Wz)\n",
    "        self.dUz = np.zeros_like(self.Uz)\n",
    "        self.dbz = np.zeros_like(self.bz)\n",
    "        self.dWr = np.zeros_like(self.Wr)\n",
    "        self.dUr = np.zeros_like(self.Ur)\n",
    "        self.dbr = np.zeros_like(self.br)\n",
    "        self.dWh = np.zeros_like(self.Wh)\n",
    "        self.dUh = np.zeros_like(self.Uh)\n",
    "        self.dbh = np.zeros_like(self.bh)\n",
    "\n",
    "    def forward(self, x, h_prev):\n",
    "        # Ensure x is 2D\n",
    "        if x.ndim == 1:\n",
    "            x = x.reshape(-1, 1)\n",
    "\n",
    "        # Gerbang update\n",
    "        self.z = sigmoid(np.dot(self.Wz, x) + np.dot(self.Uz, h_prev) + self.bz)\n",
    "\n",
    "        # Gerbang reset\n",
    "        self.r = sigmoid(np.dot(self.Wr, x) + np.dot(self.Ur, h_prev) + self.br)\n",
    "\n",
    "        # Kandidat state tersembunyi\n",
    "        self.h_tilde = tanh(np.dot(self.Wh, x) + np.dot(self.Uh, (self.r * h_prev)) + self.bh)\n",
    "\n",
    "        # State tersembunyi akhir\n",
    "        h = (1 - self.z) * h_prev + self.z * self.h_tilde\n",
    "\n",
    "        self.x, self.h_prev, self.h = x, h_prev, h\n",
    "        return h\n",
    "\n",
    "    def backward(self, dh_next):\n",
    "        dz = dh_next * (self.h_tilde - self.h_prev) * sigmoid_derivative(self.z)\n",
    "        dh_tilde = dh_next * self.z * tanh_derivative(self.h_tilde)\n",
    "        dr = dh_tilde * np.dot(self.Uh.T, self.h_prev) * sigmoid_derivative(self.r)\n",
    "\n",
    "        self.dWz += np.dot(dz, self.x.T)\n",
    "        self.dUz += np.dot(dz, self.h_prev.T)\n",
    "        self.dbz += np.sum(dz, axis=1, keepdims=True)\n",
    "\n",
    "        self.dWr += np.dot(dr, self.x.T)\n",
    "        self.dUr += np.dot(dr, self.h_prev.T)\n",
    "        self.dbr += np.sum(dr, axis=1, keepdims=True)\n",
    "\n",
    "        self.dWh += np.dot(dh_tilde, self.x.T)\n",
    "        self.dUh += np.dot(dh_tilde, (self.r * self.h_prev).T)\n",
    "        self.dbh += np.sum(dh_tilde, axis=1, keepdims=True)\n",
    "\n",
    "        dh_prev = (1 - self.z) * dh_next + np.dot(self.Uz.T, dz) + np.dot(self.Ur.T, dr) + np.dot(self.Uh.T, (dh_tilde * self.r))\n",
    "        return dh_prev\n",
    "    def update_weights(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        self.t += 1\n",
    "\n",
    "        # Buka file teks untuk menulis sejarah parameter\n",
    "        with open('parameter_history.txt', 'a') as f:\n",
    "            f.write(f\"Iteration {self.t}\\n\")\n",
    "            \n",
    "            for param in ['Wz', 'Uz', 'bz', 'Wr', 'Ur', 'br', 'Wh', 'Uh', 'bh']:\n",
    "                grad = getattr(self, 'd' + param)\n",
    "\n",
    "                # Gradient clipping\n",
    "                np.clip(grad, -1.0, 1.0, out=grad)\n",
    "\n",
    "                # Adam update\n",
    "                self.m[param] = beta1 * self.m[param] + (1 - beta1) * grad\n",
    "                self.v[param] = beta2 * self.v[param] + (1 - beta2) * (grad ** 2)\n",
    "\n",
    "                m_hat = self.m[param] / (1 - beta1 ** self.t)\n",
    "                v_hat = self.v[param] / (1 - beta2 ** self.t)\n",
    "\n",
    "                update = learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n",
    "\n",
    "                setattr(self, param, getattr(self, param) - update)\n",
    "                \n",
    "                # Identifikasi gate/aktivasi yang terkait dengan parameter\n",
    "                if 'z' in param:\n",
    "                    gate_type = \"Update Gate (Sigmoid Activation)\"\n",
    "                elif 'r' in param:\n",
    "                    gate_type = \"Reset Gate (Sigmoid Activation)\"\n",
    "                elif 'h' in param:\n",
    "                    gate_type = \"Hidden State (Tanh Activation)\"\n",
    "                else:\n",
    "                    gate_type = \"Unknown Gate\"\n",
    "\n",
    "                # Tulis informasi parameter ke file\n",
    "                f.write(f\"{param} ({gate_type}):\\n\")\n",
    "                f.write(f\"{getattr(self, param)}\\n\\n\")\n",
    "\n",
    "            f.write(\"\\n\\n\")\n",
    "\n",
    "        self.reset_gradients()\n",
    "\n",
    "\n",
    "print(\"Fungsi Perhitungan GRU Sudah disiapkan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e4209d21fada76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (12, 10, 1)\n",
      "Validation data shape: (4, 10, 1)\n",
      "Testing data shape: (5, 10, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 (Training):   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GRUCell' object has no attribute 'update_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 125\u001b[0m\n\u001b[0;32m    123\u001b[0m input_dim \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    124\u001b[0m hidden_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m--> 125\u001b[0m gru, history \u001b[38;5;241m=\u001b[39m train_gru(X_train, y_train, X_val, y_val, input_dim, hidden_dim)\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Plot training history using plotly\u001b[39;00m\n\u001b[0;32m    128\u001b[0m fig \u001b[38;5;241m=\u001b[39m go\u001b[38;5;241m.\u001b[39mFigure()\n",
      "Cell \u001b[1;32mIn[7], line 87\u001b[0m, in \u001b[0;36mtrain_gru\u001b[1;34m(X_train, y_train, X_val, y_val, input_dim, hidden_dim, epochs, learning_rate, batch_size)\u001b[0m\n\u001b[0;32m     84\u001b[0m             dh_next \u001b[38;5;241m=\u001b[39m gru\u001b[38;5;241m.\u001b[39mbackward(dh_next)\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m     gru\u001b[38;5;241m.\u001b[39mupdate_weights(learning_rate)\n\u001b[0;32m     88\u001b[0m     total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Validation\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GRUCell' object has no attribute 'update_weights'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def load_and_prepare_data(file_path, column_name, seq_length, test_size=0.2, val_size=0.2):\n",
    "    try:\n",
    "        # Load data from Excel file\n",
    "        data = pd.read_excel(file_path)\n",
    "\n",
    "        # Extract specified column\n",
    "        if column_name not in data.columns:\n",
    "            raise ValueError(f\"Column '{column_name}' not found in the Excel file.\")\n",
    "\n",
    "        raw_data = data[column_name].values\n",
    "\n",
    "        # Normalize the data\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        normalized_data = scaler.fit_transform(raw_data.reshape(-1, 1))\n",
    "\n",
    "        # Prepare sequences\n",
    "        X, y = [], []\n",
    "        for i in range(len(normalized_data) - seq_length):\n",
    "            X.append(normalized_data[i:i+seq_length])\n",
    "            y.append(normalized_data[i+seq_length])\n",
    "\n",
    "        X, y = np.array(X), np.array(y)\n",
    "\n",
    "        # Reshape X to be [samples, time steps, features]\n",
    "        X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "        # First, split into training+validation and test sets\n",
    "        X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "        # Then split the training set into training and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=val_size, random_state=42)\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}\")\n",
    "        print(f\"Validation data shape: {X_val.shape}\")\n",
    "        print(f\"Testing data shape: {X_test.shape}\")\n",
    "\n",
    "        return X_train, X_val, X_test, y_train, y_val, y_test, scaler\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "def train_gru(X_train, y_train, X_val, y_val, input_dim, hidden_dim, epochs=50, learning_rate=0.001, batch_size=32):\n",
    "    gru = GRUCell(input_dim, hidden_dim)\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_train_loss = 0\n",
    "        total_val_loss = 0\n",
    "\n",
    "        # Training\n",
    "        for i in tqdm(range(0, len(X_train), batch_size), desc=f\"Epoch {epoch+1}/{epochs} (Training)\"):\n",
    "            batch_X = X_train[i:i+batch_size]\n",
    "            batch_y = y_train[i:i+batch_size]\n",
    "\n",
    "            batch_loss = 0\n",
    "            for j in range(len(batch_X)):\n",
    "                x_seq = batch_X[j]\n",
    "                y_true = batch_y[j]\n",
    "\n",
    "                # Forward pass\n",
    "                h = np.zeros((hidden_dim, 1))\n",
    "                for t in range(x_seq.shape[0]):\n",
    "                    x_t = x_seq[t].reshape(-1, 1)\n",
    "                    h = gru.forward(x_t, h)\n",
    "\n",
    "                # Calculate loss (mean squared error)\n",
    "                y_pred = h[-1][0]\n",
    "                loss = (y_true - y_pred)**2\n",
    "                batch_loss += loss\n",
    "\n",
    "                # Backward pass\n",
    "                dh_next = 2 * (y_pred - y_true)\n",
    "                for t in reversed(range(x_seq.shape[0])):\n",
    "                    x_t = x_seq[t].reshape(-1, 1)\n",
    "                    dh_next = gru.backward(dh_next)\n",
    "\n",
    "            # Update weights\n",
    "            gru.update_weights(learning_rate)\n",
    "            total_train_loss += batch_loss\n",
    "\n",
    "        # Validation\n",
    "        for i in range(len(X_val)):\n",
    "            x_seq = X_val[i]\n",
    "            y_true = y_val[i]\n",
    "\n",
    "            # Forward pass\n",
    "            h = np.zeros((hidden_dim, 1))\n",
    "            for t in range(x_seq.shape[0]):\n",
    "                x_t = x_seq[t].reshape(-1, 1)\n",
    "                h = gru.forward(x_t, h)\n",
    "\n",
    "            # Calculate loss\n",
    "            y_pred = h[-1][0]\n",
    "            loss = (y_true - y_pred)**2\n",
    "            total_val_loss += loss\n",
    "\n",
    "        # Record losses\n",
    "        avg_train_loss = float(np.mean(total_train_loss))\n",
    "        avg_val_loss = float(np.mean(total_val_loss))\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    return gru, history\n",
    "\n",
    "# Usage\n",
    "file_path = 'test.xlsx'\n",
    "column_name = 'Terakhir_IDR'\n",
    "seq_length = 10\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, scaler = load_and_prepare_data(file_path, column_name, seq_length)\n",
    "\n",
    "input_dim = X_train.shape[2]\n",
    "hidden_dim = 100\n",
    "gru, history = train_gru(X_train, y_train, X_val, y_val, input_dim, hidden_dim)\n",
    "\n",
    "# Plot training history using plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(range(1, len(history['train_loss']) + 1)),\n",
    "    y=history['train_loss'],\n",
    "    mode='lines+markers',\n",
    "    name='Training Loss'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(range(1, len(history['val_loss']) + 1)),\n",
    "    y=history['val_loss'],\n",
    "    mode='lines+markers',\n",
    "    name='Validation Loss'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Model Loss',\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis_title='Loss',\n",
    "    legend_title='Loss Type',\n",
    "    template='plotly'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df94e53461f94019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Fungsi untuk menyimpan model dan scaler\n",
    "def save_model(gru, scaler, filename_model, filename_scaler):\n",
    "    with open(filename_model, 'wb') as f_model:\n",
    "        pickle.dump(gru, f_model)\n",
    "    with open(filename_scaler, 'wb') as f_scaler:\n",
    "        pickle.dump(scaler, f_scaler)\n",
    "\n",
    "# Fungsi untuk memuat model dan scaler\n",
    "def load_model(filename_model, filename_scaler):\n",
    "    with open(filename_model, 'rb') as f_model:\n",
    "        gru = pickle.load(f_model)\n",
    "    with open(filename_scaler, 'rb') as f_scaler:\n",
    "        scaler = pickle.load(f_scaler)\n",
    "    return gru, scaler\n",
    "\n",
    "# Simpan model dan scaler setelah pelatihan\n",
    "save_model(gru, scaler, 'gru_model.pkl', 'scaler.pkl')\n",
    "\n",
    "# Contoh memuat model dan scaler\n",
    "loaded_gru, loaded_scaler = load_model('gru_model.pkl', 'scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5284dcf275a61026",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T05:17:47.497883Z",
     "start_time": "2024-07-20T05:17:47.334929Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Fungsi tambahan untuk menghitung MAPE dan MPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def mean_percentage_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) / y_true) * 100\n",
    "\n",
    "# Load the scaler and model\n",
    "with open('gru_model.pkl', 'rb') as f:\n",
    "    loaded_gru = pickle.load(f)\n",
    "\n",
    "# Define the file paths and parameters\n",
    "file_path = 'hasil_prediksi.xlsx'  # Path to your uploaded test data file\n",
    "output_file_path = 'prediksi_hasil.xlsx'\n",
    "seq_length = 10\n",
    "\n",
    "# Load and prepare the test data\n",
    "test_data = pd.read_excel(file_path)\n",
    "test_data['Tanggal'] = pd.to_datetime(test_data['Tanggal'], format='%d/%m/%Y')  # Adjust the format to match your data\n",
    "test_data_close = test_data['Terakhir_IDR'].values  # Adjust the column name as needed\n",
    "\n",
    "# Fit the scaler with test data (or load pre-fitted scaler if available)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(test_data_close.reshape(-1, 1))  # Fit the scaler with the test data\n",
    "\n",
    "# Normalize test data using the fitted scaler\n",
    "test_data_normalized = scaler.transform(test_data_close.reshape(-1, 1))\n",
    "\n",
    "# Fungsi prediksi\n",
    "def make_predictions(model, data, seq_length):\n",
    "    predictions = []\n",
    "    h = np.zeros((model.hidden_dim, 1))  # Initial hidden state\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x_seq = data[i:i + seq_length]\n",
    "        for t in range(seq_length):\n",
    "            x_t = x_seq[t].reshape(-1, 1)\n",
    "            h = model.forward(x_t, h)\n",
    "        y_pred = h[-1][0]\n",
    "        predictions.append(y_pred)\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Buat prediksi\n",
    "predictions = make_predictions(loaded_gru, test_data_normalized, seq_length)\n",
    "\n",
    "# Denormalisasi hasil prediksi\n",
    "predictions_denormalized = scaler.inverse_transform(predictions.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Buat dataframe hasil prediksi\n",
    "results = pd.DataFrame({\n",
    "    'Tanggal': test_data['Tanggal'][seq_length:].values[:len(predictions)],\n",
    "    'data_close': test_data_close[seq_length:][:len(predictions)],\n",
    "    'prediksi_close': predictions_denormalized,\n",
    "})\n",
    "\n",
    "# Hitung selisih dan persentase selisih\n",
    "results['selisih'] = results['data_close'] - results['prediksi_close']\n",
    "results['persentase_selisih'] = (results['selisih'] / results['data_close']) * 100\n",
    "\n",
    "# Hitung MAE, RMSE, MAPE, dan MPE\n",
    "mae = mean_absolute_error(results['data_close'], results['prediksi_close'])\n",
    "rmse = np.sqrt(mean_squared_error(results['data_close'], results['prediksi_close']))\n",
    "mape = mean_absolute_percentage_error(results['data_close'], results['prediksi_close'])\n",
    "mpe = mean_percentage_error(results['data_close'], results['prediksi_close'])\n",
    "\n",
    "# Buat dataframe untuk menampilkan hasil metrik\n",
    "metrics = pd.DataFrame({\n",
    "    'Metric': ['MAE', 'RMSE', 'MAPE', 'MPE'],\n",
    "    'Value': [mae, rmse, mape, mpe]\n",
    "})\n",
    "\n",
    "# Tampilkan dataframe metrik dalam Jupyter Notebook\n",
    "metrics\n",
    "\n",
    "# Simpan hasil prediksi\n",
    "results.to_excel(output_file_path, index=False)\n",
    "print(f\"Hasil prediksi telah disimpan ke {output_file_path}\")\n",
    "\n",
    "# Visualisasi menggunakan Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Plot aktual data close\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=results['Tanggal'],\n",
    "    y=results['data_close'],\n",
    "    mode='lines',\n",
    "    name='Aktual'\n",
    "))\n",
    "\n",
    "# Plot prediksi close\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=results['Tanggal'],\n",
    "    y=results['prediksi_close'],\n",
    "    mode='lines',\n",
    "    name='Prediksi'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Perbandingan Harga Aktual vs Prediksi GRU',\n",
    "    xaxis_title='Tanggal',\n",
    "    yaxis_title='Harga (IDR)',\n",
    "    legend_title='Legenda',\n",
    "    template='plotly',\n",
    "    xaxis=dict(tickformat='%b %Y')\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0623696a387c5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T05:17:13.614909Z",
     "start_time": "2024-07-20T05:17:13.458477Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def load_data(file_path):\n",
    "    # Memuat data cryptocurrency dari file Excel\n",
    "    data = pd.read_excel(file_path)\n",
    "    data['Tanggal'] = pd.to_datetime(data['Tanggal'], format='%d/%m/%Y')\n",
    "    data.set_index('Tanggal', inplace=True)\n",
    "    return data\n",
    "\n",
    "def calculate_moving_averages(data, short_window, long_window):\n",
    "    # Menghitung moving average jangka pendek dan jangka panjang\n",
    "    data['Short_MA'] = data['Terakhir_IDR'].rolling(window=short_window, min_periods=1).mean()\n",
    "    data['Long_MA'] = data['Terakhir_IDR'].rolling(window=long_window, min_periods=1).mean()\n",
    "    return data\n",
    "\n",
    "def predict_dma(data, short_window, long_window, prediction_window):\n",
    "    # Memprediksi tren masa depan berdasarkan DMA\n",
    "    short_ma_future = [data['Short_MA'].iloc[-1]] * prediction_window\n",
    "    long_ma_future = [data['Long_MA'].iloc[-1]] * prediction_window\n",
    "    return short_ma_future, long_ma_future\n",
    "\n",
    "def save_to_excel(data, output_file_path):\n",
    "    # Menyimpan data yang telah diproses ke file Excel\n",
    "    data.to_excel(output_file_path, index=True)\n",
    "\n",
    "def plot_data(data, short_window, long_window, short_ma_future, long_ma_future):\n",
    "    # Memplot harga penutupan dan moving average menggunakan Plotly\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Plot data harga penutupan\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=data.index,\n",
    "        y=data['Terakhir_IDR'],\n",
    "        mode='lines',\n",
    "        name='Close Price'\n",
    "    ))\n",
    "\n",
    "    # Plot Short-Term MA\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=data.index,\n",
    "        y=data['Short_MA'],\n",
    "        mode='lines',\n",
    "        name=f'Short-Term MA ({short_window} days)'\n",
    "    ))\n",
    "\n",
    "    # Plot Long-Term MA\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=data.index,\n",
    "        y=data['Long_MA'],\n",
    "        mode='lines',\n",
    "        name=f'Long-Term MA ({long_window} days)'\n",
    "    ))\n",
    "\n",
    "    # Menyiapkan tanggal untuk prediksi moving average\n",
    "    future_dates = pd.date_range(start=data.index[-1], periods=len(short_ma_future) + 1, freq='D')[1:]\n",
    "\n",
    "    # Plot prediksi Short-Term MA\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=future_dates,\n",
    "        y=short_ma_future,\n",
    "        mode='lines',\n",
    "        line=dict(dash='dash'),\n",
    "        name='Predicted Short-Term MA'\n",
    "    ))\n",
    "\n",
    "    # Plot prediksi Long-Term MA\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=future_dates,\n",
    "        y=long_ma_future,\n",
    "        mode='lines',\n",
    "        line=dict(dash='dash'),\n",
    "        name='Predicted Long-Term MA'\n",
    "    ))\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title='Cryptocurrency Price with Double Moving Average',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Price (IDR)',\n",
    "        legend_title='Legend',\n",
    "        template='plotly'\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# Fungsi tambahan untuk menghitung MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Jalur file ke file Excel\n",
    "file_path = 'hasil_prediksi.xlsx'\n",
    "output_file_path = 'hasil_dma.xlsx'\n",
    "short_window = 40\n",
    "long_window = 100\n",
    "prediction_window = 10  # Jumlah hari untuk prediksi\n",
    "\n",
    "# Memuat data\n",
    "data = load_data(file_path)\n",
    "\n",
    "# Menghitung moving averages\n",
    "data = calculate_moving_averages(data, short_window, long_window)\n",
    "\n",
    "# Memprediksi DMA untuk beberapa hari ke depan\n",
    "short_ma_future, long_ma_future = predict_dma(data, short_window, long_window, prediction_window)\n",
    "\n",
    "# Menambahkan kolom selisih dan persentase selisih antara Short MA dan Long MA dengan harga asli\n",
    "data['Selisih_Short_MA'] = data['Terakhir_IDR'] - data['Short_MA']\n",
    "data['Persentase_Selisih_Short_MA'] = (data['Selisih_Short_MA'] / data['Terakhir_IDR']) * 100\n",
    "\n",
    "data['Selisih_Long_MA'] = data['Terakhir_IDR'] - data['Long_MA']\n",
    "data['Persentase_Selisih_Long_MA'] = (data['Selisih_Long_MA'] / data['Terakhir_IDR']) * 100\n",
    "\n",
    "# Menghitung metrik\n",
    "metrics = {\n",
    "    'MAE_Short_MA': mean_absolute_error(data['Terakhir_IDR'], data['Short_MA']),\n",
    "    'RMSE_Short_MA': np.sqrt(mean_squared_error(data['Terakhir_IDR'], data['Short_MA'])),\n",
    "    'MAPE_Short_MA': mean_absolute_percentage_error(data['Terakhir_IDR'], data['Short_MA']),\n",
    "    'MSE_Short_MA': mean_squared_error(data['Terakhir_IDR'], data['Short_MA']),\n",
    "    'MAE_Long_MA': mean_absolute_error(data['Terakhir_IDR'], data['Long_MA']),\n",
    "    'RMSE_Long_MA': np.sqrt(mean_squared_error(data['Terakhir_IDR'], data['Long_MA'])),\n",
    "    'MAPE_Long_MA': mean_absolute_percentage_error(data['Terakhir_IDR'], data['Long_MA']),\n",
    "    'MSE_Long_MA': mean_squared_error(data['Terakhir_IDR'], data['Long_MA']),\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(list(metrics.items()), columns=['Metric', 'Value'])\n",
    "\n",
    "# Menyimpan data yang telah diproses ke file Excel baru\n",
    "save_to_excel(data, output_file_path)\n",
    "\n",
    "# Memplot data\n",
    "plot_data(data, short_window, long_window, short_ma_future, long_ma_future)\n",
    "\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a93866a9b603188",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T05:18:33.791955Z",
     "start_time": "2024-07-20T05:18:33.615948Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Buat prediksi menggunakan model GRU yang sudah dimuat\n",
    "gru_predictions = make_predictions(loaded_gru, test_data_normalized, seq_length)\n",
    "gru_predictions_denormalized = scaler.inverse_transform(gru_predictions.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Hitung DMA (Double Moving Average)\n",
    "data = calculate_moving_averages(test_data, short_window, long_window)\n",
    "predictions_denormalized = data['Short_MA'].iloc[seq_length:].values\n",
    "\n",
    "# Update dataframe hasil dengan prediksi GRU dan DMA\n",
    "results = pd.DataFrame({\n",
    "    'Tanggal': test_data['Tanggal'][seq_length:].values,\n",
    "    'data_close': test_data_close[seq_length:],\n",
    "    'prediksi_close_dma': predictions_denormalized,\n",
    "    'prediksi_close_gru': gru_predictions_denormalized,\n",
    "})\n",
    "\n",
    "# Hitung selisih dan persentase selisih\n",
    "results['selisih_dma'] = results['data_close'] - results['prediksi_close_dma']\n",
    "results['persentase_selisih_dma'] = (results['selisih_dma'] / results['data_close']) * 100\n",
    "results['selisih_gru'] = results['data_close'] - results['prediksi_close_gru']\n",
    "results['persentase_selisih_gru'] = (results['selisih_gru'] / results['data_close']) * 100\n",
    "\n",
    "# Hitung metrik kinerja\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def mean_percentage_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) / y_true) * 100\n",
    "\n",
    "mae_dma = mean_absolute_error(results['data_close'], results['prediksi_close_dma'])\n",
    "rmse_dma = np.sqrt(mean_squared_error(results['data_close'], results['prediksi_close_dma']))\n",
    "mape_dma = mean_absolute_percentage_error(results['data_close'], results['prediksi_close_dma'])\n",
    "mpe_dma = mean_percentage_error(results['data_close'], results['prediksi_close_dma'])\n",
    "\n",
    "mae_gru = mean_absolute_error(results['data_close'], results['prediksi_close_gru'])\n",
    "rmse_gru = np.sqrt(mean_squared_error(results['data_close'], results['prediksi_close_gru']))\n",
    "mape_gru = mean_absolute_percentage_error(results['data_close'], results['prediksi_close_gru'])\n",
    "mpe_gru = mean_percentage_error(results['data_close'], results['prediksi_close_gru'])\n",
    "\n",
    "# Tabel perbandingan metrik kinerja\n",
    "metrics_comparison = pd.DataFrame({\n",
    "    'Metric': ['MAE', 'RMSE', 'MAPE', 'MPE'],\n",
    "    'DMA': [mae_dma, rmse_dma, mape_dma, mpe_dma],\n",
    "    'GRU': [mae_gru, rmse_gru, mape_gru, mpe_gru]\n",
    "})\n",
    "\n",
    "# Simpan hasil prediksi dan perbandingan metrik ke file Excel\n",
    "with pd.ExcelWriter(output_file_path) as writer:\n",
    "    results.to_excel(writer, sheet_name='Predictions', index=False)\n",
    "    metrics_comparison.to_excel(writer, sheet_name='Metrics_Comparison', index=False)\n",
    "\n",
    "print(f\"Hasil prediksi dan perbandingan metrik telah disimpan ke {output_file_path}\")\n",
    "\n",
    "# Visualisasi perbandingan prediksi menggunakan Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Plot harga aktual\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=results['Tanggal'],\n",
    "    y=results['data_close'],\n",
    "    mode='lines',\n",
    "    name='Actual Close Price'\n",
    "))\n",
    "\n",
    "# Plot prediksi DMA\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=results['Tanggal'],\n",
    "    y=results['prediksi_close_dma'],\n",
    "    mode='lines',\n",
    "    name='DMA Predicted Close Price'\n",
    "))\n",
    "\n",
    "# Plot prediksi GRU\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=results['Tanggal'],\n",
    "    y=results['prediksi_close_gru'],\n",
    "    mode='lines',\n",
    "    name='GRU Predicted Close Price'\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Perbandingan Prediksi DMA dan GRU untuk harga USDT Tether Coin',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Price (IDR)',\n",
    "    legend_title='Legend',\n",
    "    template='plotly',\n",
    "    xaxis=dict(tickformat='%b %Y')\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "metrics_comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3496c69aad2bd633",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
